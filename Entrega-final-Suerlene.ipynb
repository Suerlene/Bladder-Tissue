{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323a36d5",
   "metadata": {},
   "source": [
    "Este trabalho tem como objetivo a construção de uma pipeline completa de supervisão fraca e/ou detecção de erros de anotação aplicada ao conjunto de dados Endoscopic Bladder Tissue Classification Dataset, disponível publicamente na plataforma Kaggle por meio do link: https://www.kaggle.com/datasets/aryashah2k/endoscopic-bladder-tissue-classification-dataset/data. \n",
    "Trata-se de um conjunto de dados de imagens endoscópicas da bexiga, criado com o objetivo de auxiliar na classificação de tecidos vesicais em diferentes categorias, visando o suporte ao diagnóstico médico de câncer de bexiga.\n",
    "As imagens foram capturadas por endoscopia durante procedimentos clínicos reais e estão organizadas nas classes de tecido:\n",
    "HGC (High-Grade Cancer), LGC (Low-Grade Cancer), NST (Neoplastic Suspected Tissue) e NTL (Normal Tissue Lesion).\n",
    "Neste contexto, a proposta visa aplicar técnicas de aprendizado com supervisão fraca, como a detecção de rótulos ruidosos (anotações incorretas), a fim de identificar possíveis inconsistências nas anotações originais. Essa abordagem tem como finalidade melhorar a qualidade dos dados, o que pode refletir diretamente em uma melhor performance dos modelos de classificação treinados sobre esse conjunto.\n",
    "O dataset é composto por 1.754 imagens, distribuídas entre subconjuntos de treino, validação e teste, e organizadas nas quatro classes mencionadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c015422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cleanlab in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (1.6.1)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy~=1.22 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from cleanlab) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.53.0 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from cleanlab) (4.67.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from cleanlab) (2.2.3)\n",
      "Requirement already satisfied: termcolor>=2.4.0 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from cleanlab) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from pandas>=1.4.0->cleanlab) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from pandas>=1.4.0->cleanlab) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from pandas>=1.4.0->cleanlab) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from tqdm>=4.53.0->cleanlab) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\su_20\\anaconda3\\envs\\meu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->cleanlab) (1.17.0)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/39.4 MB 1.9 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 1.8/39.4 MB 4.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.1/39.4 MB 5.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 4.5/39.4 MB 5.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 5.8/39.4 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.1/39.4 MB 5.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.4/39.4 MB 5.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 9.7/39.4 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 11.0/39.4 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.3/39.4 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.6/39.4 MB 5.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 14.9/39.4 MB 5.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 16.3/39.4 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 17.6/39.4 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.9/39.4 MB 5.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 20.2/39.4 MB 5.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.2/39.4 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.3/39.4 MB 5.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.1/39.4 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.1/39.4 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 25.4/39.4 MB 5.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.7/39.4 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 28.0/39.4 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/39.4 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.9/39.4 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 32.2/39.4 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/39.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.1/39.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.4/39.4 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.0/39.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cleanlab scikit-learn opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84426e",
   "metadata": {},
   "source": [
    "Foi realizada uma detecção automática de rótulos possivelmente errados com a biblioteca Cleanlab.\n",
    "Etapas da pipeline: \n",
    "\n",
    "1. Leitura do dataset\n",
    "   - O arquivo `annotations.csv` é carregado, contendo os caminhos das imagens, o tipo de tecido anotado e a indicação se a amostra pertence ao conjunto de treino ou teste.\n",
    "   - Cada imagem recebe um rótulo numérico correspondente à sua classe (`HGC`, `LGC`, `NST` ou `NTL`).\n",
    "\n",
    "2. Extração de características das imagens\n",
    "   - As imagens são processadas com OpenCV:\n",
    "     - Redimensionadas para 64×64 pixels.\n",
    "     - Convertidas para escala de cinza.\n",
    "     - Extraído um histograma de intensidade com 128 bins (features).\n",
    "   - O vetor resultante é normalizado para cada imagem.\n",
    "\n",
    "3. Validação cruzada (out-of-sample predictions)\n",
    "   - Uma validação cruzada estratificada de 5 folds é aplicada.\n",
    "   - Para cada fold, é treinado um modelo `RandomForestClassifier` e obtidas as probabilidades preditas para as amostras do fold de validação.\n",
    "   - Esse processo gera previsões realistas, pois cada imagem foi avaliada por um modelo que não a viu durante o treinamento.\n",
    "\n",
    "4. Aplicação do Cleanlab\n",
    "   - Com as predições de probabilidade, o Cleanlab identifica exemplos com baixa autoconfiança (probabilidade do rótulo anotado ser menor do que a de outro rótulo).\n",
    "   - O método `find_label_issues` retorna os índices dos exemplos com maior chance de estarem anotados incorretamente.\n",
    "\n",
    "5. Exibição de rótulos suspeitos\n",
    "   - Os 10 exemplos mais suspeitos são exibidos com:\n",
    "     - Caminho da imagem.\n",
    "     - Rótulo original.\n",
    "     - Classe mais provável segundo o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e03247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo features das imagens...\n",
      "Realizando validação cruzada...\n",
      "Executando Cleanlab com predições reais...\n",
      "Cleanlab encontrou 64 rótulos potencialmente errados.\n",
      "\n",
      "Top 10 rótulos suspeitos:\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NST\\case_013_pt_001_frame_0087.png\n",
      "Rótulo original: NST\n",
      "Predição mais provável: HGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NST\\case_010_pt_002_frame_0051.png\n",
      "Rótulo original: NST\n",
      "Predição mais provável: HGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NTL\\case_022_pt_002_frame_0037.png\n",
      "Rótulo original: NTL\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NST\\case_017_pt_004_frame_0224.png\n",
      "Rótulo original: NST\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NST\\case_009_pt_001_frame_0095.png\n",
      "Rótulo original: NST\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NTL\\case_014_pt_004_frame_0026.png\n",
      "Rótulo original: NTL\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NST\\case_007_pt_002_frame_0041.png\n",
      "Rótulo original: NST\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NST\\case_007_pt_002_frame_0053.png\n",
      "Rótulo original: NST\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NTL\\case_014_pt_001_frame_0045.png\n",
      "Rótulo original: NTL\n",
      "Predição mais provável: LGC\n",
      "------------------------------\n",
      "Imagem: C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue\\NTL\\cys_case_10_pt1_0729.png\n",
      "Rótulo original: NTL\n",
      "Predição mais provável: NST\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "N_SPLITS = 5  # número de folds para validação cruzada\n",
    "DATA_DIR = 'C:/Users/su_20/Downloads/archive/EndoscopicBladderTissue'\n",
    "ANNOTATIONS_FILE = os.path.join(DATA_DIR, \"annotations.csv\")\n",
    "IMAGE_CLASSES = [\"HGC\", \"LGC\", \"NST\", \"NTL\"]\n",
    "class_to_id = {name: i for i, name in enumerate(IMAGE_CLASSES)}\n",
    "id_to_class = {i: name for i, name in enumerate(IMAGE_CLASSES)}\n",
    "\n",
    "# Carrega anotações\n",
    "df = pd.read_csv(ANNOTATIONS_FILE)\n",
    "df['image_path'] = df.apply(lambda row: os.path.join(DATA_DIR, row['tissue type'], row['HLY']), axis=1)\n",
    "df['label'] = df['tissue type'].map(class_to_id)\n",
    "df_train = df[df['sub_dataset'] == 'train'].reset_index(drop=True)\n",
    "\n",
    "# Função de extração de features com OpenCV \n",
    "def extract_features(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return np.zeros(128)\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        hist = cv2.calcHist([gray], [0], None, [128], [0, 256]).flatten()\n",
    "        return hist / (hist.sum() + 1e-7)\n",
    "    except:\n",
    "        return np.zeros(128)\n",
    "\n",
    "print(\"Extraindo features das imagens...\")\n",
    "X = np.array([extract_features(p) for p in df_train['image_path']])\n",
    "y = df_train['label'].values\n",
    "\n",
    "# Validação cruzada para gerar predições out-of-sample\n",
    "print(\"Realizando validação cruzada...\")\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "pred_probs = np.zeros((len(y), len(IMAGE_CLASSES)))\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_val = X[train_idx], X[test_idx]\n",
    "    y_train = y[train_idx]\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_probs[test_idx] = model.predict_proba(X_val)\n",
    "\n",
    "# Detecção de rótulos suspeitos\n",
    "print(\"Executando Cleanlab com predições reais...\")\n",
    "label_issues = find_label_issues(\n",
    "    labels=y,\n",
    "    pred_probs=pred_probs,\n",
    "    return_indices_ranked_by=\"self_confidence\"\n",
    ")\n",
    "\n",
    "print(f\"Cleanlab encontrou {len(label_issues)} rótulos potencialmente errados.\")\n",
    "\n",
    "# Mostrar os 10 principais\n",
    "print(\"\\nTop 10 rótulos suspeitos:\")\n",
    "for idx in label_issues[:10]:\n",
    "    row = df_train.iloc[idx]\n",
    "    original_label = id_to_class[row['label']]\n",
    "    predicted_label_id = np.argmax(pred_probs[idx])\n",
    "    predicted_label_name = id_to_class[predicted_label_id]\n",
    "    print(f\"Imagem: {row['image_path']}\")\n",
    "    print(f\"Rótulo original: {original_label}\")\n",
    "    print(f\"Predição mais provável: {predicted_label_name}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e7d0b",
   "metadata": {},
   "source": [
    "Após identificar rótulos potencialmente errados com o Cleanlab, nesta etapa realizou-se uma comparação entre o desempenho dos modelos: modelo treinado com os rótulos originais e o modelo treinado com rótulos corrigidos (retagging).\n",
    "Etapas da avaliação:\n",
    "\n",
    "1. Correção de rótulos (retagging automatizado)\n",
    "   - Os rótulos suspeitos (detectados pelo Cleanlab) são substituídos pela classe com maior probabilidade predita pelo modelo.\n",
    "   - Isso cria um vetor `y_corrected` com rótulos ajustados.\n",
    "\n",
    "2. Divisão dos dados\n",
    "   - Os dados são divididos em 70% para treinamento e 30% para teste, mantendo a proporção entre as classes.\n",
    "   - São criados dois conjuntos de rótulos de treino:\n",
    "     - `y_train_original`: com rótulos originais.\n",
    "     - `y_train_corrected`: com rótulos corrigidos nas posições detectadas.\n",
    "\n",
    "3. Treinamento e predição\n",
    "   - Dois modelos `RandomForestClassifier` são treinados:\n",
    "     - Um com os rótulos originais.\n",
    "     - Outro com os rótulos corrigidos.\n",
    "   - Ambos são testados no mesmo conjunto de teste para garantir uma comparação justa.\n",
    "\n",
    "4. Avaliação do desempenho\n",
    "   - São calculadas as seguintes métricas para os dois modelos:\n",
    "     - Acurácia\n",
    "     - MCC (Matthews Correlation Coefficient)\n",
    "     - Relatório de classificação, contendo:\n",
    "       - *Precision*\n",
    "       - *Recall*\n",
    "       - *F1-score* para cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29557652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Desempenho com rótulos originais:\n",
      "Acurácia: 0.8386\n",
      "MCC: 0.7663\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         HGC       0.80      0.82      0.81        93\n",
      "         LGC       0.79      0.90      0.84       145\n",
      "         NST       0.95      0.93      0.94       114\n",
      "         NTL       0.83      0.19      0.31        26\n",
      "\n",
      "    accuracy                           0.84       378\n",
      "   macro avg       0.84      0.71      0.72       378\n",
      "weighted avg       0.84      0.84      0.83       378\n",
      "\n",
      "\n",
      " Desempenho com rótulos corrigidos (retagging):\n",
      "Acurácia: 0.8175\n",
      "MCC: 0.7349\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         HGC       0.78      0.78      0.78        93\n",
      "         LGC       0.76      0.87      0.81       145\n",
      "         NST       0.93      0.92      0.93       114\n",
      "         NTL       0.83      0.19      0.31        26\n",
      "\n",
      "    accuracy                           0.82       378\n",
      "   macro avg       0.83      0.69      0.71       378\n",
      "weighted avg       0.82      0.82      0.80       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# Rótulos antes da correção\n",
    "y_original = y.copy()\n",
    "\n",
    "# Rótulos corrigidos: apenas onde há problemas detectados\n",
    "y_corrected = y.copy()\n",
    "for idx in label_issues:\n",
    "    y_corrected[idx] = np.argmax(pred_probs[idx])  # troca pelo rótulo mais provável\n",
    "\n",
    "# Separar conjunto de teste (30%) para avaliação final\n",
    "X_train, X_test, y_train_original, y_test = train_test_split(X, y_original, test_size=0.3, random_state=42, stratify=y_original)\n",
    "_, _, y_train_corrected, _ = train_test_split(X, y_corrected, test_size=0.3, random_state=42, stratify=y_original)\n",
    "\n",
    "# Treinar modelo com dados originais\n",
    "clf_original = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_original.fit(X_train, y_train_original)\n",
    "y_pred_original = clf_original.predict(X_test)\n",
    "\n",
    "# Treinar modelo com dados retaggeados\n",
    "clf_corrected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_corrected.fit(X_train, y_train_corrected)\n",
    "y_pred_corrected = clf_corrected.predict(X_test)\n",
    "\n",
    "# Avaliação \n",
    "print(\"\\n Desempenho com rótulos originais:\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_original):.4f}\")\n",
    "print(f\"MCC: {matthews_corrcoef(y_test, y_pred_original):.4f}\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_original, target_names=IMAGE_CLASSES))\n",
    "\n",
    "print(\"\\n Desempenho com rótulos corrigidos (retagging):\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_corrected):.4f}\")\n",
    "print(f\"MCC: {matthews_corrcoef(y_test, y_pred_corrected):.4f}\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_corrected, target_names=IMAGE_CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525dc130",
   "metadata": {},
   "source": [
    "Com base na análise das métricas, observa-se que o processo de retagging não resultou em uma melhoria de desempenho. Tanto a acurácia (que passou de 83,86% para 81,75%) quanto o coeficiente de correlação de Matthews (MCC), que caiu de 0,7663 para 0,7349, apresentaram uma leve redução após a correção automática dos rótulos.\n",
    "\n",
    "Em contextos sensíveis como o da área médica, essa queda sugere que o retagging automatizado deve ser encarado com cautela. A revisão manual dos rótulos suspeitos identificados por ferramentas como o Cleanlab ainda se mostra essencial, de modo a verificar se as sugestões de correção realmente fazem sentido do ponto de vista clínico e diagnóstico. A triagem automatizada é útil para destacar possíveis inconsistências, mas não substitui o julgamento especializado de profissionais da saúde.\n",
    "\n",
    "Diversos fatores podem ter contribuído para os resultados observados. O primeiro é o número reduzido de amostras do conjunto de dados — apenas 1.754 imagens — o que limita a capacidade do modelo de aprender padrões de forma robusta e compromete a estabilidade das estimativas de incerteza, fundamentais para a detecção de erros de anotação. Ferramentas como o Cleanlab tendem a se beneficiar de bases de dados maiores e mais diversas, que permitam uma identificação mais precisa de ruídos nos rótulos.\n",
    "\n",
    "Além disso, o desequilíbrio entre as classes representa uma dificuldade adicional. A classe NTL, por exemplo, possui apenas 26 amostras no conjunto de teste. Esse volume extremamente baixo dificulta tanto o aprendizado do modelo quanto a avaliação do desempenho, além de tornar a detecção de erros nessa classe particularmente desafiadora.\n",
    "\n",
    "Outro fator relevante está relacionado à natureza das features extraídas. Neste trabalho, optou-se por utilizar descritores manuais baseados em histogramas de intensidade, uma abordagem simples, porém limitada para capturar a complexidade visual de imagens médicas. Essa limitação pode ter impactado negativamente a qualidade das predições do classificador, afetando, por consequência, a eficácia do Cleanlab na identificação de rótulos incorretos.\n",
    "\n",
    "Portanto, os resultados indicam que, embora o uso de técnicas de supervisão fraca e detecção automática de erros seja promissor, sua aplicação em contextos médicos requer cautela. Para alcançar melhores resultados, seria recomendável o uso de features mais robustas, bases de dados mais extensas e balanceadas, além de uma análise humana criteriosa para validar quaisquer alterações nos rótulos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
